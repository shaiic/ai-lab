{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "    \n",
    "# mnist\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src='../static/img/logo.jpg' align='right' style=\"width:260px;height:60px;display:block\"/>\n",
    "</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](../static/img/minist.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST数据集(Mixed National Institute of Standards and Technology database)是美国国家标准与技术研究院收集整理的大型手写数字数据库,包含60,000个示例的训练集以及10,000个示例的测试集.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "train: (55000, 784)\n",
      "test: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#coding : utf8\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data #读数据集\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "\n",
    "'''\n",
    "1.数据\n",
    "读取数据,划分训练集测试集labels,features\n",
    "'''\n",
    "\n",
    "data = input_data.read_data_sets('./MNIST_data', one_hot= True) #读取数据\n",
    "print('train:',data.train.images.shape)\n",
    "print('test:',data.test.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取部分数据训练与测试\n",
    "train_x, train_y = data.train.images[:5000], data.train.labels[:5000]\n",
    "test_x, test_y = data.test.images[:1000], data.test.labels[:1000]\n",
    "train_x.shape\n",
    "# # 全部数据\n",
    "# train_x, train_y = data.train.images, data.train.labels\n",
    "# test_x, test_y = data.test.images, data.test.labels\n",
    "# train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''\n",
    "2.参数\n",
    "本文使用两层隐藏层,各层neuron个数分别为:\n",
    "input_layer: 28*28 (features of train_x or test_x)\n",
    "hidden_layer1: 256\n",
    "hidden_layer2: 128\n",
    "output_layer: 10\n",
    "'''\n",
    "n_input = 28 * 28\n",
    "n_hidden_layer_1 = 256\n",
    "n_hidden_layer_2 = 128\n",
    "n_output_layer = 10\n",
    " \n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_output_layer])\n",
    " \n",
    "# 生成指定shape的随机张量\n",
    "w = {\n",
    "    'w1': tf.Variable(tf.random_normal([n_input, n_hidden_layer_1],seed=10001),dtype= tf.float32),\n",
    "    'w2': tf.Variable(tf.random_normal([n_hidden_layer_1, n_hidden_layer_2],seed=10001),dtype= tf.float32),\n",
    "    'w_out': tf.Variable(tf.random_normal([n_hidden_layer_2, n_output_layer],seed=10001),dtype= tf.float32)\n",
    "}\n",
    "# 生成全零的偏置张量\n",
    "b = {\n",
    "    'b1': tf.Variable(tf.zeros([1,n_hidden_layer_1]), dtype= tf.float32),\n",
    "    'b2': tf.Variable(tf.zeros([1,n_hidden_layer_2]), dtype= tf.float32),\n",
    "    'b_out': tf.Variable(tf.zeros([1,n_output_layer]), dtype= tf.float32)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''\n",
    "3.前向传播\n",
    "'''\n",
    " \n",
    "def forward_propagation(_x, _w, _b):\n",
    "    layer1 = tf.nn.relu(tf.add(tf.matmul(_x, _w['w1']), _b['b1']))\n",
    "    layer2 = tf.nn.relu(tf.add(tf.matmul(layer1, _w['w2']), _b['b2']))\n",
    "    return tf.add(tf.matmul(layer2, _w['w_out']), _b['b_out'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-990fcc2536ee>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "4.损失函数\n",
    "'''\n",
    "\n",
    "learn_rate = 0.001\n",
    "y_predict = forward_propagation(x, w, b)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= y_predict, labels= y))\n",
    "optm = tf.train.GradientDescentOptimizer(learn_rate).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "'''\n",
    "5.评价\n",
    "'''\n",
    "result = tf.equal(tf.math.argmax(y_predict, 1), tf.math.argmax(y, 1))\n",
    "# tf.cast改变张量类型\n",
    "acc = tf.reduce_mean(tf.cast(result, dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1, 损失值:436.051, 分类准确率:0.308\n",
      "epoch:  2, 损失值:184.253, 分类准确率:0.447\n",
      "epoch:  3, 损失值:120.799, 分类准确率:0.523\n",
      "epoch:  4, 损失值:93.766, 分类准确率:0.581\n",
      "epoch:  5, 损失值:78.687, 分类准确率:0.605\n",
      "epoch:  6, 损失值:68.820, 分类准确率:0.624\n",
      "epoch:  7, 损失值:61.666, 分类准确率:0.638\n",
      "epoch:  8, 损失值:55.892, 分类准确率:0.654\n",
      "epoch:  9, 损失值:51.352, 分类准确率:0.667\n",
      "epoch: 10, 损失值:47.514, 分类准确率:0.673\n",
      "epoch: 11, 损失值:44.357, 分类准确率:0.691\n",
      "epoch: 12, 损失值:41.602, 分类准确率:0.694\n",
      "epoch: 13, 损失值:39.138, 分类准确率:0.700\n",
      "epoch: 14, 损失值:37.010, 分类准确率:0.706\n",
      "epoch: 15, 损失值:35.036, 分类准确率:0.713\n",
      "epoch: 16, 损失值:33.292, 分类准确率:0.719\n",
      "epoch: 17, 损失值:31.686, 分类准确率:0.724\n",
      "epoch: 18, 损失值:30.233, 分类准确率:0.727\n",
      "epoch: 19, 损失值:28.918, 分类准确率:0.733\n",
      "epoch: 20, 损失值:27.685, 分类准确率:0.734\n",
      "epoch: 21, 损失值:26.551, 分类准确率:0.736\n",
      "epoch: 22, 损失值:25.520, 分类准确率:0.738\n",
      "epoch: 23, 损失值:24.520, 分类准确率:0.738\n",
      "epoch: 24, 损失值:23.599, 分类准确率:0.739\n",
      "epoch: 25, 损失值:22.771, 分类准确率:0.739\n",
      "epoch: 26, 损失值:21.952, 分类准确率:0.742\n",
      "epoch: 27, 损失值:21.216, 分类准确率:0.741\n",
      "epoch: 28, 损失值:20.512, 分类准确率:0.744\n",
      "epoch: 29, 损失值:19.872, 分类准确率:0.742\n",
      "epoch: 30, 损失值:19.244, 分类准确率:0.748\n",
      "epoch: 31, 损失值:18.645, 分类准确率:0.752\n",
      "epoch: 32, 损失值:18.081, 分类准确率:0.755\n",
      "epoch: 33, 损失值:17.530, 分类准确率:0.753\n",
      "epoch: 34, 损失值:17.006, 分类准确率:0.758\n",
      "epoch: 35, 损失值:16.481, 分类准确率:0.756\n",
      "epoch: 36, 损失值:15.997, 分类准确率:0.761\n",
      "epoch: 37, 损失值:15.521, 分类准确率:0.763\n",
      "epoch: 38, 损失值:15.073, 分类准确率:0.764\n",
      "epoch: 39, 损失值:14.650, 分类准确率:0.763\n",
      "epoch: 40, 损失值:14.230, 分类准确率:0.769\n",
      "epoch: 41, 损失值:13.826, 分类准确率:0.768\n",
      "epoch: 42, 损失值:13.417, 分类准确率:0.767\n",
      "epoch: 43, 损失值:13.057, 分类准确率:0.769\n",
      "epoch: 44, 损失值:12.690, 分类准确率:0.767\n",
      "epoch: 45, 损失值:12.327, 分类准确率:0.766\n",
      "epoch: 46, 损失值:11.996, 分类准确率:0.769\n",
      "epoch: 47, 损失值:11.655, 分类准确率:0.768\n",
      "epoch: 48, 损失值:11.354, 分类准确率:0.769\n",
      "epoch: 49, 损失值:11.021, 分类准确率:0.767\n",
      "epoch: 50, 损失值:10.730, 分类准确率:0.773\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "6.训练和保存\n",
    "'''\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "save_path = './000/'\n",
    "if not save_path:\n",
    "    os.makedir(save_path)\n",
    "saver = tf.train.Saver(max_to_keep=3)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(epochs):\n",
    "        cost = count = 0.0\n",
    "        for batch_index in range(0, train_y.shape[0], batch_size):\n",
    "            count += 1\n",
    "            feed = {x: train_x[batch_index: batch_index + batch_size], y: train_y[batch_index: batch_index + batch_size]}\n",
    "            sess.run(optm, feed_dict= feed)\n",
    "            cost += sess.run(loss, feed_dict= feed)\n",
    "        cost /= count\n",
    "        # 测试集精度\n",
    "        feed_test = {x: test_x, y: test_y}\n",
    "        accuracy = sess.run(acc, feed_dict= feed_test)\n",
    "        # 保存模型\n",
    "        # saver.save(sess, os.path.join(save_path,global_step = i+1))\n",
    "        saver.save(sess, save_path, global_step = i+1)\n",
    "        if i%1 == 0 or i==epochs:\n",
    "            print('epoch:{:>3d}, 损失值:{:>6.3f}, 分类准确率:{:.3f}'.format(i+1, cost, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
